{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import os\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms.functional import pad\n",
    "from torchvision import transforms, datasets, utils as vutils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Params \n",
    "\n",
    "# Image path\n",
    "training_data_full = \"data/training2/full\"\n",
    "training_data_empty = \"data/training2/empty\"\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 200\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 48\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 1\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.00011\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "# Which GPU to use.\n",
    "gpu = 1  # 0 first one 1 second one.\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "\n",
    "# Train Test and Validate partitions\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14686\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "class WormClassDataset(Dataset):\n",
    "    \"\"\" Full and emty are the paths to the data contianing\n",
    "    the list of images. 0 = empty, 1 = full.\n",
    "    Transform is the pytorch transformations to apply\n",
    "    \"\"\"\n",
    "    def __init__(self, full_path, empty_path, transform=None):\n",
    "        self.full_path = full_path\n",
    "        self.full = os.listdir(full_path)\n",
    "        self.empty_path = empty_path\n",
    "        self.empty = os.listdir(empty_path)\n",
    "        \n",
    "        self.balace_data()\n",
    "        self.data = self.full + self.empty\n",
    "        self.remove_ds()\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def balace_data(self):\n",
    "        \"\"\"Takes images form the two classes and curates the data so it's 50/50\"\"\"\n",
    "        d = [self.full, self.empty]\n",
    "        small = np.argmin([len(d[0]), len(d[1])])\n",
    "        \n",
    "        new_idxs = random.sample(range(0, len(d[not small])), len(d[small])) \n",
    "        new = [d[not small][i] for i in new_idxs]\n",
    "        print(len(new))\n",
    "                                       \n",
    "        if not small:\n",
    "            self.empty = new\n",
    "        elif small:\n",
    "            self.full = new\n",
    "            \n",
    "    def remove_ds(self):\n",
    "        if '.DS_Store' in self.data:\n",
    "            self.data.remove('.DS_Store')\n",
    "            \n",
    "    def __len__(self):\n",
    "        data_count = len(self.data)\n",
    "        return data_count\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        if idx < len(self.full):\n",
    "            _class = 1\n",
    "            img_name = os.path.join(self.full_path, self.data[idx])  \n",
    "        else:\n",
    "            _class = 0\n",
    "            img_name = os.path.join(self.empty_path, self.data[idx])  \n",
    "\n",
    "        image = io.imread(img_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # image = cv2.normalize(image, image, 0, 255, cv2.NORM_MINMAX)\n",
    "        # mask = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 22)\n",
    "        # mask = cv2.bitwise_not(mask)\n",
    "        # image = cv2.bitwise_and(image, image, mask=mask)\n",
    "        \n",
    "        sample = image\n",
    "        # plt.imshow(image)\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return {'image': sample, 'class': _class}\n",
    "\n",
    "    \n",
    "    \n",
    "class SquarePad:\n",
    "    def __call__(self, image):\n",
    "        w, h = image.size\n",
    "        max_wh = np.max([w, h])\n",
    "        hp = int((max_wh - w) / 2)\n",
    "        vp = int((max_wh - h) / 2)\n",
    "        padding = (hp, vp, hp, vp)\n",
    "        return pad(image, padding, 0, 'constant')\n",
    "    \n",
    "    \n",
    "test = WormClassDataset(training_data_full, training_data_empty)\n",
    "b = test.__getitem__(9)\n",
    "print(b['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14686\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Resize, convert to grayscale, convert to tensor, normalize, and rotate.\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        # SquarePad(),\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5))\n",
    "    ])\n",
    "\n",
    "worm_class_dataset = WormClassDataset(training_data_full, training_data_empty, transform=data_transform)\n",
    "\n",
    "\n",
    "# Init gpu device if present.\n",
    "device = torch.device(f\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAEwCAYAAADfOUbNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjrUlEQVR4nO2db4il53ner/v8mzP/Vtq1VEWVVEtNjFOXunZZTIL7ISg1uE6I9MGUmBAUEOhLC3bjEsstFAL94HyJE2hxELGJCiFy4oTKmJSiqgohEGSvLTm1LWwppmpkr7QrrVY7/86cmXPufpgjutJ7Xbvvs3Pm7D6j6wfLzjz77vM+z3vec88793Wu+47MhDHG1Ernei/AGGMOg4OYMaZqHMSMMVXjIGaMqRoHMWNM1TiIGWOq5lBBLCI+GhHfj4gXIuLheS3KGGPaEtf6ObGI6AL4AYCPAHgJwDcAfCIzv6f+T3d1NXunTl3T+a4JFaJD7HkazUMn81tOA3Xpm8tATOdwOnU9CtZxoyCvR8FeUuxP3R5zgcyt9tIR9x57Hafd9seqcflyF1yP4telYI6d8y+9mpm3vn28137qBh8C8EJm/hAAIuIxAPcBkEGsd+oU7vjUvz3EKcuYrvCrkX0+HqPmK9t/4/C/cXcm/PZQATLJDdkdiWPF8tiNsLfK76TumK+PreMomXb5+tj1U9eju8vHJ0vkfH1+rHpd5vGDJPabY/1Nvu/hRT6+t9K8HqNT/DWcLPN1sHtB7U/dH+z16u3wY3s7fG56vh2+729/4dMvsvHDvEPvAPB3l33/0mzMGGMWxpEn9iPioYg4ExFnJltbR306Y8w7jMMEsR8BuOuy7++cjb2FzHwkM09n5unu6uohTmeMMU0OE8S+AeA9EXFPRAwA/DKAr85nWcYY045rTuxn5n5E/BsA/wNAF8CXMvO71zSXSOgeFjmvHGdzlJ3zSNXMI0LtkSVulUhxpOsg0lano5LN81zR/Enyjstu+8T5wfHt5lXHKqSgoe7pG+RaH0adRGb+OYA/n9NajDGmGH9i3xhTNQ5ixpiqcRAzxlTNoXJi1wJLtmePJDBV0rAgyRhDfnBnwMcnJGk97fM4X5wELYAldLuFHiD2yXCVlJ8MRAKZbr39p+oBfj3KzidsNnO4zot2JKhzTgf82MkSv6b7y83xyVDMIa41+3S++mS+uqePSuRRQofCT2LGmKpxEDPGVI2DmDGmahzEjDFV4yBmjKmahauTFGr3aW8NArgS2V/e41N0eeGk0aA5uVqHUraCFFaUiuoRogrqMaQqyF4XUXOKWYMAoFOgqk6FksaYyNpeN3AlRwh1UtxLTIUEgP0VMjYsu087/K1RBFMttYVNrKNgDoWfxIwxVeMgZoypGgcxY0zVOIgZY6rGQcwYUzWLVSdD+CSZktbnasvgJt7O5sRqs/3Ncp9LMK9cXKfjybxgS2UFG6dkjpiILkPCe8Y8aaozj1JymHpX0l1JUeJvPJibeGXVsQXXml3n2Syt51DXoz8qUFQLXxfmi50O+PnGwlM5PtGcY7LO5drOdvvnFOWzVB5JVbSREWIOpnarjlUKP4kZY6rGQcwYUzUOYsaYqnEQM8ZUzcIT+9Q2xBKsIml46gRvwPuTN73WGFvqkMqA0Il9kOSjtD91+PiUWEI6e2U/K4oKCSr7ExUYipZRdL7pkkgs7zb3Lq1cfeElYslwuZf217or5lCJZWadycJihHReVRRRzLF/qnlfx0Bcu20xOVuHECmmQmQrYV8ILr2dw9vE/CRmjKkaBzFjTNU4iBljqsZBzBhTNQ5ixpiquWGLIkIoeudf58riaNyUVoYDbjvaH3OJjSk81IoEUCUTALobzXWXKjAlNqASxbFUWYx9pnAKqxRRIQ+Ob78OpUiXINVkeqyy0/DjWQG/zlgcK9qfKSWyCFJ4M8f8+qvih/R1EY80rL2bnOM6tMHzk5gxpmocxIwxVeMgZoypGgcxY0zVOIgZY6pmwepktlaPVDG3Cbi8c3GnuZXOgEt3U3IsAHTX2vexmlzi6+iRgnrdHTHHMh8vKTanCtYx5UgpY6l8fkRpim2hThaoYGodUaJOChUsVVFE1ipNFeoT74oOeR1L30CsWKXyLCqoQqzUcqGSMtR7U81xVOqkUocVfhIzxlSNg5gxpmocxIwxVeMgZoypmhvCdsQL+IkEskj45xLpEKSS3sLSNCEJ/6JkM3hSfrLM16GK3rFEr7QMiU5KQZLnylaiCjxi2MzcToZiL+KaBksKq6S87GBE5m195GzuOViaWNcqZS+SxSpJnc5Qdh9hKYtdYjtiXcSuAJtbnm8OxTSPEj+JGWOqxkHMGFM1DmLGmKpxEDPGVI2DmDGmam4IdZK1bNOKiFCDiHIUIkYrhZPVflNtxJR6ypRF1fKqqEhhqZ2jQFFS7b5Wb2r6bIZ93gZvtMdvpa03mt6q0kKTrAig3J+6TkSB1YqlUMbZOYU6PBm0nyNVpzqhfE5Imzh1P5Yojup8ylLG1O6SVnUA0CnWmdkcxhhTMQ5ixpiqcRAzxlSNg5gxpmquGsQi4ksRcS4ivnPZ2KmIeCIinp/9ffJol2mMMZw26uQfAPjPAP7rZWMPA3gyMz8XEQ/Pvv/M1acK7pNkrcGEYiNnZnMQjxkAdEdqlmZMn66UrWOy0lw4WxugFSWGVNKU75EV2mMqH7QPsddp7mV/wn/ujcf8VqJKZIkKibLrJCFzl87LivVRxRK68GNJwT+lLDK1UPpiCyj1SDJ1fR5FEdU1lcdf7YDM/EsAF942fB+AR2dfPwrg/rLTGmPMfLjW+H1bZp6dff0ygNvUgRHxUESciYgzk83NazydMcZwDv0QmpkJqMLmQGY+kpmnM/N0d23tsKczxpi3cK1B7JWIuB0AZn+fm9+SjDGmPddqO/oqgAcAfG729+Ot/ldCWIxY0pVPoTrDsDmUXUJ3gGk+UE6XxKGqsF+B7UIV1OvsNn+2TETnJoiEPyvmqOw+0eUqyi6xEqkE/mSTvzAxIj8n52ChUmKJ6nYURL4oT2STwpvifBNx35Qk4JW4xe5fZfdRiXb13iiBJvYLH4vYHKWvS5uPWPwRgL8G8N6IeCkiHsRB8PpIRDwP4F/MvjfGmIVz1SexzPyE+Kefn/NajDGmGH9i3xhTNQ5ixpiqcRAzxlTNDVEUcR4todgcvZ2yQnFzgdmAiKp1JajFSNiLVEs5rjiKdncFViKlQnbf4LcSu9ZToaTNxV6kILUcSxU6biVqXxwT4GpcZ1y2jpJ2a0Xz8nqXSBElWHtC2aruCN9zfhIzxlSNg5gxpmocxIwxVeMgZoypGgcxY0zVLFadzPYFEJXKoYoDdkfNebvNjmMAdME61gqrxAt5cFKi2EyFv44UUJTnFPuW7c/Iz6fSVmkT5kfd5C+MKjTZIXNMhCdQKVglHj3Zuox1wZMeWs5+s/ucvE9LWpdFoXrNYNd5Xsyj4OJRcoMvzxhjroyDmDGmahzEjDFV4yBmjKmaG8J2xFDJxOzxhGlHWGfoHCIZO10i2d++yELv8fNRG1BXZKyJkAAAHVGkkDEd883kmBUjFMlm0WWIjatCjiVJcnVsSWK/JHEOcAtaqe1of7m9zaYELWIdfu5FMw97Uem+/SRmjKkaBzFjTNU4iBljqsZBzBhTNQ5ixpiqWaw62QFyiSg8RK1ShfOUDWh8oqnoTYWdQxWsY63EVNHBnPDx/nJT8loZ8qp3wwGXx/qd5l5e3Vilx+5siVZp5Jqqa1dSjFApR3urYm4itCoFqzcHhVPBlMjuLj+W2YsAYUsrsMEBokikUo3ngLIjsfdAFD7SsLnV9VBQ5Vm1SVTrKDvcGGNuLBzEjDFV4yBmjKkaBzFjTNU4iBljqmbB3smk6gVTIpmKCUB6Gac3Ncf3llTFOrE6sjalgcWAr2MwaPa9evfNr9Nj//7KG3R8d9J8WTZGXLIZCfWpu938+TQp8GQqqL/0CnR2m+so/ck5Dz8eUyJLvJqA2Lvy+Ql1suR8JcUIS32gJf5EdZ3YuFKNSxRY+ekBgZ/EjDFV4yBmjKkaBzFjTNU4iBljqmaxif0ATcxPV8ixHWHnWG4mzgGeUB91eTK8pOsPsxGp8wHAyZVmi6VBlx+r2J02X5bdPf5SxS7fC0v0TsWx0zWeuQ1S+JEl6q9EScKZFR2U84rXsMMdXjQJXdypiB2vxAHZjYmP0zkKku9KbimxAam1qWvNjpdzCImMJvxdFNEY807CQcwYUzUOYsaYqnEQM8ZUjYOYMaZqFq5Otm1pphREpQresr7VGHtd2Gx2dgZ0fLLTvBzqfH9vfZOOr/eb/pZBp8w3M5425ZmJaElX0kKNFfU7OFgoWERZLLW30HUI9U+tjyteonWfNIq1R9leqC1N3KdSWSy4fmUFBg+/b8VUXOtuQTHNEtyyzRjzjsJBzBhTNQ5ixpiqcRAzxlSNg5gxpmoWrE4mgiiGyZQ3oXzs7nDp6PVus8/W9ib3Tqo2bIO1pvHuJ0+9Ro+9e42Pj4nv8dVd3m7t/2yeouOb4+a6lTo5XVGuuebxsqAh8Ugq9tfEHKqQICnOqNBqHGkNJpYhCwyScSICXxGmRMa+8ASKa90puNbzoFTpK4GpzMpneZT4ScwYUzUOYsaYqnEQM8ZUzVWDWETcFRFPRcT3IuK7EfHJ2fipiHgiIp6f/X3y6JdrjDFvpU1ifx/ApzPzWxGxDuCbEfEEgF8D8GRmfi4iHgbwMIDPXGmiCKA3aHpI9naasZQV5AOAaZdnKlkSf7rFRYDuCV4579SJpnXpvSdeocf+o+Uf0/EXd29pjP14+yZ67NlLJ+g4K4CobFgpLDz75DorQliX6NxDnrBWxSon3abFS51PkT22R35/pCiKyJL4U+4+k8lwVoBS2b72heDCLE3KyqUtTaQ7mBBF+LVTgkSZhSrIS6DWMY+OVYqrPoll5tnM/Nbs6w0AzwG4A8B9AB6dHfYogPuPaI3GGCMpyolFxN0APgjgaQC3ZebZ2T+9DOC2+S7NGGOuTusgFhFrAP4UwKcy89Ll/5aZCVFWICIeiogzEXFmcqn565oxxhyGVkEsIvo4CGB/mJl/Nht+JSJun/377QDOsf+bmY9k5unMPN09wT/0aYwx10obdTIAfBHAc5n525f901cBPDD7+gEAj89/ecYYc2XaqJMfBvCrAP53RDw7G/v3AD4H4I8j4kEALwL4V1ebKKeBPWIbyjFRJ5WaoVRLZgkptECs9Jsy0T1L5+mx/2z4f1vP+wzuouOqDdt43N4NFkPRbo3Yu6ZjITOpcTpvSaE+0BZ9WfrxRNK+T5mtpiOhWvaIdWkOlpzSOZh6Ny0saEgVxzmsIyclSqawYc1BhSyd46rvlsz8K+iykT9fdjpjjJkv/sS+MaZqHMSMMVXjIGaMqRoHMWNM1Sy2KOIUyFFTRumQwnlKWZwqXap7+GJsS92m/+8n+m/QY98/4P3FLk7px+UoqtAh80kqVbA34MY71mpu641m4UhAq08pfJL0WPF6sXWneA07wu/J5ph0+a2bm0K9Jp5F1TqupFWa9gqKa0qUReVv7OyKZwyiRCZRgYsRreogFN8YES+pet8WXNPSwop+EjPGVI2DmDGmahzEjDFV4yBmjKmaxSb2M2hBPJYEVYXiVLeYZA2TVGE6YbM5v7XWGPv+6HZ67Lnhs3T8wqRZkWhjj3ddUol9RpfYiACewAeAXqcgKb8kkq4lCe45iBRqnO1dJYonw4I1F/4IL7GxKQvPDc1UiDNK+CHXrySBD8ynO5KfxIwxVeMgZoypGgcxY0zVOIgZY6rGQcwYUzWLVScFrAhaV7TC6o7az7srYvT+gKuTr77SbKH237rvp8e+e/AqHX9x3GzZdmFrhR472eGXn9lvlDq5Ntyl46Ox8pA0CdHCrkML5wmlqkBpVXPMg6lQpHOJnFMU31N2H3afKhV9ygVpqfQVwdYtbHdSUS0oPFiiyjJ7F6CvEz9f+2MBP4kZYyrHQcwYUzUOYsaYqnEQM8ZUjYOYMaZqbgh1soQuF+OoojEZclWlc56rk51J83K8PDlFj33i5D/mCyFsjwatjwW4h1Cpk/NgaZlLR8zbuT/h104qjmy80F9X4jFVLexoW8DCn+FBXgLl/VMKJyuiWNpakCqcqmWbUPrYHB3xiQBFSbu6DimgeHDOw80L+EnMGFM5DmLGmKpxEDPGVI2DmDGmahab2A/wTi1kTHWi2VvjCcL+ZnNs6QJfxoA3MALAkq7cR/HXp+6m47esbzXGVGJaFQFkhQ5VkUOVaN+fHr7gIlt3ib1Iofat4IUVy4SOZLYcYYUpsb2oIoB6DlYUVMwt3gOUggT+wTnbFyJViXa2PiVSsAS+Gp+W6WB+EjPG1I2DmDGmahzEjDFV4yBmjKkaBzFjTNUs2HaU1HYxXWJKkyhoSBREAOjuNFWR5Qv82Jt/sK2X2IAXNHztZLO9GwD8+Ceal1S1iFMKW4nFaLTHX8ISq06NlCqc84C1KFNt35hFCSiz1GSvYI9i3thV6mRzTFmopuI9d6NwvO90Y8yxx0HMGFM1DmLGmKpxEDPGVI2DmDGmahbvnew3ZZsksXRC2pYButNUd0y2cp4f23/pNTFLk7VVfol2buU9ubZ6zfEUHrjOCb4b5pPcFSrkmO27EDXHPlFVVfFDqRayIoBCfZ1HK7d5zFHkWRSoAoNMnVeKpbpv0Gm/PuoZBcA8nMqvrGA+SbY/AJgOCtq+2TtpjHkn4SBmjKkaBzFjTNU4iBljqmaxif1OokMS9rQDjEj+qgTy3kZ7P8fk7Mt0PPebxQiH69x2tH4LL5Y4WW6uY/eksBeJ8R7Z+8aWsBdt8nXEoL11aW+Hz0GT5CpxrooDkr2o17DUnnVU5BJfX1GnIpXYZ1YideuKBH5nuXmfSjbbvy+m/DYoKhKpUKLBtGWR1CvhJzFjTNU4iBljqsZBzBhTNQ5ixpiquWoQi4hhRHw9Ir4dEd+NiN+cjd8TEU9HxAsR8eWIKPycrTHGHJ426uQugHszczMi+gD+KiL+O4BfB/D5zHwsIn4PwIMAvnC1yZgyFd328oe0lZB5d24VMfqfvJdP8dK55tp2dvmxY1WckYwt8zUzWw8A7A+P5gFZXjs1PiXjBZaXecHbxJUpluy+S2KBAyCVVnqdxLUrshKpayrWsbTc7K2mimAqHZMpjtpu1d5CNV3h13TKRX7eOm677P6/6tF5wJtdHfuzPwngXgBfmY0/CuD+ojMbY8wcaBXyIqIbEc8COAfgCQB/C+BiZr4Z6F8CcMeRrNAYY65AqyCWmZPM/ACAOwF8CMBPtz1BRDwUEWci4sxko9kd2xhjDkPRL5+ZeRHAUwB+FsDNEfFmTu1OAD8S/+eRzDydmae766uHWasxxjRoo07eGhE3z75eBvARAM/hIJh9fHbYAwAeP6I1GmOMpI06eTuARyOii4Og98eZ+bWI+B6AxyLiPwF4BsAXrzZRdBKDQTvfl1Jbxjv8kxxBPGmjW7jasvFTvN3aTVsjcjD/Fbi3zVWY/iYp8CjUyT2hTrICiCWqrEQVNBy1fyBP8UEaXSyx/bFlBQ35mpk39wDi4Vwu8+cyb2cyBRe6OCArClrafm51OG6M6dZ9fH2dpsCJyYrwjKrWceS1jSG//n2iqAJcoZ+i7NNaVw1imfk3AD5Ixn+Ig/yYMcZcN/yJfWNM1TiIGWOqxkHMGFM1Cy2KGAC6pMCdSuIXQZKMk3WeuL30bp5Qz+6tjbHhqzfTY3dv5nOwJL7sIlOQyO6p7k8iKcyS5Mkq0EF31ZEF/46I0gQ3QxVWzHH7e6ykoKRCJcPZHpUYMY/OTXNBWajYXkQBSyXo0ff+btm+/SRmjKkaBzFjTNU4iBljqsZBzBhTNQ5ixpiqWaw6GUCvczjlRylYtMCdOHbrH/C5d081Y/ry+SV6bHeHz72/TNamWlAJywpDqTvqem5sDRtjSm1MYRXJDjlerVlaiZrXVLfja28DUsrddIff0h3SukwpiNIyVIBSfLtEiWSKPQBMxDNGjxQRnYzKrDqdAuVTXg9SzFG9P0ve96WquJ/EjDFV4yBmjKkaBzFjTNU4iBljqsZBzBhTNQv2TiZ6Qolpiyqutod++0lOCB/XyebaNm7iqs/SeS457q22b2OlWnUxP9lSn695OODXgxVW3Onza9Rd5nPTIoCFyhFTHJWCpVQ6hlLulHraHREvKVNfAUyUV1CouIelZN8AsE8WqPzHSlkUNlqKVLXZmDiW3Y8Av8d6/JaW+EnMGFM1DmLGmKpxEDPGVI2DmDGmahZsO0os95tZu52CpHyPdHoBgG0yxjqpADqxfOvJjcbY6ARf28X+Op+bFNRTdhqIZGxJkcgVcj0BYH/Y3PvuMt/L8jK/puNu8/aQCWTZ7ah5rVUiu20nLAAYj0WiWKyjt9NekJgORCK7T8aFOKMEBnad1DVV12mfHC9fF2GtmrK9KISeEWjOoYpS7oqpc9Q8vju27cgY8w7CQcwYUzUOYsaYqnEQM8ZUjYOYMaZqFqpOdiOxNlA6xVvZ6x4+vm6DW4aU6sOUvpPDnUOvY3/K97K9yQsuMgVL2TYUTAVeEpatobA0sUJ2petgqOuv1sHUOK6nlhU0DKW6HWGrNFYkUsl/ympWhLAXTVUbQULsC6WVXWtVrFJ9UqBQiWT4ScwYUzUOYsaYqnEQM8ZUjYOYMaZqHMSMMVWzcO/koNNUYphiuTvhS9tTFetEcUCGUgsvbK00xtaHXE29/cSl1uc7e+lE62MBruQoTXd7lfshmaq6t1r2M4u1BjtsUcvS8ylkIUFVaJKocaptmVQ4C1rsKUq8k+paj4hCrLyrci9EGI9d4X+V7fjI3N3DX6P9YVnLPD+JGWOqxkHMGFM1DmLGmKpxEDPGVM3Cux0Nuk0rBR0jAgAAbLCMpEIk+0djngzfHjVtSiq5+p6bzrdexuujZTq+0R3y/7DX/NkyJWMAsLnGrwdL7KsCilIsIfSJFemGQiSyJ+RST1liGrqQIEMmvVVCfQ6WJiYEqEKfSuhgo6zIIQB0pGZGijMOhDhTIIqUWKL4KowxpiIcxIwxVeMgZoypGgcxY0zVOIgZY6pm4UUR13vtiiJCHMeUTAB4bbTaGNsT9iJlO6LLEFaYJbGO9d6oMXbbSnNtAHDhEh+Pi+3Vwk2s0fGzREVUFqq+2GOJaqmuNT2fUDjVOhjKdtQR6thkveDntWrDRkh1bEFxRlUwcIuo5UBZscSSdohKae1v8vH95eYepytl6qsquFiCn8SMMVXjIGaMqRoHMWNM1TiIGWOqpnUQi4huRDwTEV+bfX9PRDwdES9ExJcjgmchjTHmCClRJz8J4DkAb1b4+y0An8/MxyLi9wA8COALV5ogIqmqN+g0x5bIGKBVQaZOzoNSr+Cp3lZj7F1LzTEAGAz4XiZb7RWbmHJl69Jq06+pfKAlquBRol5bNr4x4p5R5SHsrDYNgOpYpRaqwoMl6yiZdzzmb8/VIWtYx69dScNB1cKuJyZJUgBxT91K7YXuYlo9iUXEnQB+AcDvz74PAPcC+MrskEcB3H8E6zPGmCvS9tfJ3wHwGwDe/FH+LgAXM/PN8P8SgDvYf4yIhyLiTEScGb3e8jNixhjTkqsGsYj4RQDnMvOb13KCzHwkM09n5unhyYIyOsYY04I2ObEPA/iliPgYgCEOcmK/C+DmiOjNnsbuBPCjo1umMcZwrhrEMvOzAD4LABHxcwD+XWb+SkT8CYCPA3gMwAMAHr/6XCG7GL0dldhnIgDAk7/KNtMTyfoJSXwrO82ru+2FhI19/gS6s8MF3dXN5pjI32MsGimtrDV/dT8xbFqiAH2d5mEloscKIUEVwhyTzSvrmOz6QzsK8TXLBD4bV8X+RgXFElWHph3+XtkaNO8bZcOKgdjjqH2mfSJ+gWLFEnub/HWZiA5GrABlZ7fsk1+H+ZzYZwD8ekS8gIMc2RcPMZcxxlwTRQbwzPwLAH8x+/qHAD40/yUZY0x7/Il9Y0zVOIgZY6rGQcwYUzULLYqYCOxO251yXRymVEuGUsGU/WZ/2hzfF8rd5l77z7ypY5W9pbvTVGxiUNYabI0UQFzv8w8bX5is0HG2d1Ukch6ogpdMnZwHXLG8AkSJVIUEO9t87ulS8x5L5ToWyufuTrPQ4dIy76sW4l7PAh9QisvUIe6n3g5f81TUZixpj6fwk5gxpmocxIwxVeMgZoypGgcxY0zVOIgZY6pmoeqkgimWG/tDfqzwXm6OmwqgbNkmVKkJGR+JS/T6qFl08ErrYyjlaG+tqfBMhYI1XWnvWdwoUFQV82i3dpToYoQlxS2VL7M5t2rZNuWCL0Auk1I4s8/XzJRIXiiR39MAMCa+zMm6uB/F+2hwiam19FA5Pg/8JGaMqRoHMWNM1TiIGWOqxkHMGFM1C03sT7O9heTSHk/sq/+/s9f0NagEviqox7rLqGJzb6i5h+2tOioJPSGawWQgEtYi+cssQ9t8BpmsZ+tWCXzVqagEVRSRoQpbyg5SBRajfZ4jBwqaEio7WJBihLErEvuikCBL4quCl6M9/hbfGzTfL2rN6pXt7TT30hWdkULpKuTtrNah8JOYMaZqHMSMMVXjIGaMqRoHMWNM1TiIGWOq5oawHTFUIcELI+7nYCpMiSIF8FZdqijipMvnZmrmmmpRJpS03ZOkcN4SV2wGa0pKazIa88p0fVJAEShrw6YoURzVa84sZQqlJjNK7w+Gso6VPB8o2xH22tvmVNs9eU6y7o5QwKdKtVxurkNaqAoudWmhRD+JGWOqxkHMGFM1DmLGmKpxEDPGVI2DmDGmahaqTnaCq1VMlVIF/F7f5sUItzebx+sCeZyyFl5clWKKl1L5blrlRrNXTjX30hlwle/EKvfMMZRnVBW9W+k3i+8pj6RSIVUbNsZro1U6vjFqXg+1F+WpLEEpz+w1V/dYKlGWFkXkh8aYK30bW01fcYkfGODrXhf30u6AzzFaI15j0YYwhXjKfJIBodYK/CRmjKkaBzFjTNU4iBljqsZBzBhTNTes7UjZKFSikifly5K8zHZUKg6UWFlk5yDSzUZZlFTBRWWXWjQs4a8KW6rXXCWtS2AJ/3nYjuaBKhgY+8LCQ+5TtRc1zuxZPWmh4vfeDrEpKYvSUXJjvIrGGHONOIgZY6rGQcwYUzUOYsaYqnEQM8ZUTWQuTk2IiPMAXpx9ewuAVxd28sVz3PcHeI/HgZr29+7MvPXtgwsNYm85ccSZzDx9XU6+AI77/gDv8ThwHPbnXyeNMVXjIGaMqZrrGcQeuY7nXgTHfX+A93gcqH5/1y0nZowx88C/ThpjqmbhQSwiPhoR34+IFyLi4UWf/yiIiC9FxLmI+M5lY6ci4omIeH7298nrucbDEBF3RcRTEfG9iPhuRHxyNn6c9jiMiK9HxLdne/zN2fg9EfH07H79ckQMrvdaD0NEdCPimYj42uz76ve30CAWEV0A/wXAvwTwPgCfiIj3LXINR8QfAPjo28YeBvBkZr4HwJOz72tlH8CnM/N9AH4GwL+evW7HaY+7AO7NzH8K4AMAPhoRPwPgtwB8PjN/CsDrAB68fkucC58E8Nxl31e/v0U/iX0IwAuZ+cPMHAN4DMB9C17D3MnMvwRw4W3D9wF4dPb1owDuX+Sa5klmns3Mb82+3sDBm+AOHK89ZmZuzr7tz/4kgHsBfGU2XvUeI+JOAL8A4Pdn3weOwf4WHcTuAPB3l33/0mzsOHJbZp6dff0ygNuu52LmRUTcDeCDAJ7GMdvj7FetZwGcA/AEgL8FcDEz3yyoVfv9+jsAfgP/v9Deu3AM9ufE/gLIAwm4ehk4ItYA/CmAT2Xmpcv/7TjsMTMnmfkBAHfi4LeGn76+K5ofEfGLAM5l5jev91rmzaIru/4IwF2XfX/nbOw48kpE3J6ZZyPidhz8dK+WiOjjIID9YWb+2Wz4WO3xTTLzYkQ8BeBnAdwcEb3Z00rN9+uHAfxSRHwMwBDACQC/i2Owv0U/iX0DwHtmisgAwC8D+OqC17AovgrggdnXDwB4/Dqu5VDMcidfBPBcZv72Zf90nPZ4a0TcPPt6GcBHcJD7ewrAx2eHVbvHzPxsZt6ZmXfj4H33vzLzV3Ac9peZC/0D4GMAfoCDfMN/WPT5j2hPfwTgLIA9HOQVHsRBvuFJAM8D+J8ATl3vdR5if/8cB78q/g2AZ2d/PnbM9vh+AM/M9vgdAP9xNv4PAXwdwAsA/gTA0vVe6xz2+nMAvnZc9udP7BtjqsaJfWNM1TiIGWOqxkHMGFM1DmLGmKpxEDPGVI2DmDGmahzEjDFV4yBmjKma/wdMK6M/9J4xMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show sample image from the dataset.\n",
    "\n",
    "rand_saple = worm_class_dataset.__getitem__(np.random.randint(0, len(worm_class_dataset)))\n",
    "plt.imshow(torch.reshape(rand_saple['image'], (image_size, image_size, 1)))\n",
    "print(rand_saple['class'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the actual dataloader\n",
    "### Also will split data into train test and validate\n",
    "___Will shuffle the data, and batch it___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23498 2937 2937\n",
      "5874 2937 2937\n",
      "23498 2937\n"
     ]
    }
   ],
   "source": [
    "train_count = round(len(worm_class_dataset) * train_ratio)\n",
    "val_test_count = len(worm_class_dataset) - train_count\n",
    "val_count = round(len(worm_class_dataset) * val_ratio)\n",
    "test_count = round(len(worm_class_dataset) * test_ratio)\n",
    "# Training and val + test dataset.\n",
    "\n",
    "print(train_count, test_count, val_count)\n",
    "\n",
    "# The datasets needed for training\n",
    "seed = torch.manual_seed(42)\n",
    "seed2 = torch.manual_seed(55)\n",
    "\n",
    "train_set, val_test_set = torch.utils.data.random_split(worm_class_dataset, [train_count, val_test_count], generator=seed)\n",
    "print(len(val_test_set), val_count, test_count)\n",
    "val_set, test_set = torch.utils.data.random_split(val_test_set, [val_count, test_count], generator=seed2)\n",
    "\n",
    "# Training DATA-LOADER\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_set, batch_size=1, shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "print(len(train_set), len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin designing one of the model options\n",
    "___Will try a few things:____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WormClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim):\n",
    "        super(WormClassifier, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(1, 12, 2, 1, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(12, 12, 2, 1, padding=1)\n",
    "        \n",
    "        self.conv2_1 = nn.Conv2d(12, 24, 2, 1, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(24, 24, 2, 1, padding=1)\n",
    "        \n",
    "        self.conv3_1 = nn.Conv2d(24, 36, 2, 1, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(36, 36, 2, 1, padding=1)\n",
    " \n",
    "        self.conv4_1 = nn.Conv2d(36, 48, 2, 1, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(48, 48, 2, 1, padding=1)\n",
    "        # self.conv4_2 = nn.Conv2d(48, 48, 5, 1, padding=2)\n",
    "        \n",
    "        \n",
    "        # self.conv5_1 = nn.Conv2d(48, 60, 5, 1, padding=2)\n",
    "        # self.conv5_2 = nn.Conv2d(60, 60, 5, 1, padding=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(768, 1)\n",
    "        # self.fc2 = nn.Linear(256, 1)\n",
    "        # self.fc3 = nn.Linear(90, 1)\n",
    "        # self.fc3 = nn.Linear(2048, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "            \n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # x = F.relu(self.conv5_1(x))\n",
    "        # x = F.relu(self.conv5_2(x))\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        # print(x.shape)\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "class WormClassifier2(nn.Module):\n",
    "    # IMG SIZE 24 x 24\n",
    "    def __init__(self, dim):\n",
    "        super(WormClassifier2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 12, 5, 1, 2)\n",
    "        self.conv2 = nn.Conv2d(12, 24, 5, 1, 2)\n",
    "        self.conv3 = nn.Conv2d(24, 36, 5, 1, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(36, 1)\n",
    "        # self.fc2 = nn.Linear(36, 1)\n",
    "    #         self.conv5_1 = nn.Conv2d(512, 512, 5, 1 padding=2)\n",
    "    #         self.conv5_2 = nn.Conv2d(512, 512, 5, 1 padding=2)\n",
    "\n",
    "        # self.fc1 = nn.Linear(512 * 4 * 4, 256 * 4 * 4)\n",
    "        # self.fc2 = nn.Linear(4096, 2048)\n",
    "        # self.fc3 = nn.Linear(2048, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), 4)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WormClassifier(\n",
      "  (conv1_1): Conv2d(1, 12, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "  (conv1_2): Conv2d(12, 12, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2_1): Conv2d(12, 24, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2_2): Conv2d(24, 24, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3_1): Conv2d(24, 36, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3_2): Conv2d(36, 36, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4_1): Conv2d(36, 48, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4_2): Conv2d(48, 48, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=768, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "device = \"cuda:1\"\n",
    "# device = \"cpu\"\n",
    "\n",
    "model = WormClassifier(image_size)\n",
    "model = model.to(device)\n",
    "# model.apply(weights_init)  # Random starting weights.\n",
    "# sample = train_set[3][\"image\"].unsqueeze(1).to(device)\n",
    "# model(sample).shape\n",
    "\n",
    "print(model)\n",
    "\n",
    "# model2 = WormClassifier2(image_size).to(device)\n",
    "# model2(sample).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose loss function and setup optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BCELoss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "empty_label = 0\n",
    "full_label = 1\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(beta1, 0.999))  # betas=(beta1, 0.999)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)  # betas=(beta1, 0.999)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_dataloader):\n",
    "            inputs, labels = data[\"image\"], data[\"class\"]\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.unsqueeze(1).to(torch.float32)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            for label, prediction in zip(labels, outputs):\n",
    "                prediction = prediction.to(torch.int)\n",
    "                if label == prediction:\n",
    "                    correct += 1\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                total += 1\n",
    "\n",
    "            # inputs, labels = data[\"image\"], data[\"class\"]\n",
    "    \n",
    "    return(correct / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 / 500] accuracy = 0.4916581545795029 loss = 0.6931737661361694\n",
      "[2 / 500] accuracy = 0.4916581545795029 loss = 0.6931195855140686\n",
      "[3 / 500] accuracy = 0.4916581545795029 loss = 0.6931462287902832\n",
      "[4 / 500] accuracy = 0.4916581545795029 loss = 0.6931623816490173\n",
      "[5 / 500] accuracy = 0.4916581545795029 loss = 0.6932204961776733\n",
      "[6 / 500] accuracy = 0.4916581545795029 loss = 0.6930113434791565\n",
      "[7 / 500] accuracy = 0.4916581545795029 loss = 0.6929863095283508\n",
      "[8 / 500] accuracy = 0.4916581545795029 loss = 0.693118155002594\n",
      "[9 / 500] accuracy = 0.4916581545795029 loss = 0.6931670904159546\n",
      "[10 / 500] accuracy = 0.4916581545795029 loss = 0.6933271288871765\n",
      "[11 / 500] accuracy = 0.4916581545795029 loss = 0.6930459141731262\n",
      "[12 / 500] accuracy = 0.4916581545795029 loss = 0.6931016445159912\n",
      "[13 / 500] accuracy = 0.4916581545795029 loss = 0.6930211782455444\n",
      "[14 / 500] accuracy = 0.4916581545795029 loss = 0.6931455731391907\n",
      "[15 / 500] accuracy = 0.4916581545795029 loss = 0.6939198970794678\n",
      "[16 / 500] accuracy = 0.4916581545795029 loss = 0.6932290196418762\n",
      "[17 / 500] accuracy = 0.4916581545795029 loss = 0.6931571960449219\n",
      "[18 / 500] accuracy = 0.4916581545795029 loss = 0.6931517124176025\n",
      "[19 / 500] accuracy = 0.4916581545795029 loss = 0.693250834941864\n",
      "[20 / 500] accuracy = 0.4916581545795029 loss = 0.6933972239494324\n",
      "[21 / 500] accuracy = 0.4916581545795029 loss = 0.6931345462799072\n",
      "[22 / 500] accuracy = 0.4916581545795029 loss = 0.6929433345794678\n",
      "[23 / 500] accuracy = 0.4916581545795029 loss = 0.6932763457298279\n",
      "[24 / 500] accuracy = 0.4916581545795029 loss = 0.6929449439048767\n",
      "[25 / 500] accuracy = 0.4916581545795029 loss = 0.6931672096252441\n",
      "[26 / 500] accuracy = 0.4916581545795029 loss = 0.69310462474823\n",
      "[27 / 500] accuracy = 0.4916581545795029 loss = 0.6932223439216614\n",
      "[28 / 500] accuracy = 0.4916581545795029 loss = 0.6931125521659851\n",
      "[29 / 500] accuracy = 0.4916581545795029 loss = 0.6931715607643127\n",
      "[30 / 500] accuracy = 0.4916581545795029 loss = 0.6931056976318359\n",
      "[31 / 500] accuracy = 0.4916581545795029 loss = 0.6928864121437073\n",
      "[32 / 500] accuracy = 0.4916581545795029 loss = 0.6931447982788086\n",
      "[33 / 500] accuracy = 0.4916581545795029 loss = 0.693300187587738\n",
      "[34 / 500] accuracy = 0.4916581545795029 loss = 0.6930985450744629\n",
      "[35 / 500] accuracy = 0.4916581545795029 loss = 0.6932090520858765\n",
      "[36 / 500] accuracy = 0.4916581545795029 loss = 0.6931235790252686\n",
      "[37 / 500] accuracy = 0.4916581545795029 loss = 0.6931748390197754\n",
      "[38 / 500] accuracy = 0.4916581545795029 loss = 0.6928569078445435\n",
      "[39 / 500] accuracy = 0.4916581545795029 loss = 0.6932450532913208\n",
      "[40 / 500] accuracy = 0.4916581545795029 loss = 0.693404495716095\n",
      "[41 / 500] accuracy = 0.4916581545795029 loss = 0.6931807994842529\n",
      "[42 / 500] accuracy = 0.4916581545795029 loss = 0.6931521892547607\n",
      "[43 / 500] accuracy = 0.4916581545795029 loss = 0.6931319832801819\n",
      "[44 / 500] accuracy = 0.4916581545795029 loss = 0.6930043697357178\n",
      "[45 / 500] accuracy = 0.4916581545795029 loss = 0.6932777762413025\n",
      "[46 / 500] accuracy = 0.4916581545795029 loss = 0.6932253241539001\n",
      "[47 / 500] accuracy = 0.4916581545795029 loss = 0.6932457685470581\n",
      "[48 / 500] accuracy = 0.4916581545795029 loss = 0.6931231617927551\n",
      "[49 / 500] accuracy = 0.4916581545795029 loss = 0.6931631565093994\n",
      "[50 / 500] accuracy = 0.4916581545795029 loss = 0.6931060552597046\n",
      "[51 / 500] accuracy = 0.4916581545795029 loss = 0.6931452751159668\n",
      "[52 / 500] accuracy = 0.4916581545795029 loss = 0.6931157112121582\n",
      "[53 / 500] accuracy = 0.4916581545795029 loss = 0.6937826871871948\n",
      "[54 / 500] accuracy = 0.4916581545795029 loss = 0.6932313442230225\n",
      "[55 / 500] accuracy = 0.4916581545795029 loss = 0.6930356621742249\n",
      "[56 / 500] accuracy = 0.4916581545795029 loss = 0.6930442452430725\n",
      "[57 / 500] accuracy = 0.4916581545795029 loss = 0.6930829882621765\n",
      "[58 / 500] accuracy = 0.4916581545795029 loss = 0.6928711533546448\n",
      "[59 / 500] accuracy = 0.4916581545795029 loss = 0.6931094527244568\n",
      "[60 / 500] accuracy = 0.4916581545795029 loss = 0.6931572556495667\n",
      "[61 / 500] accuracy = 0.4916581545795029 loss = 0.6932863593101501\n",
      "[62 / 500] accuracy = 0.4916581545795029 loss = 0.6931261420249939\n",
      "[63 / 500] accuracy = 0.4916581545795029 loss = 0.6930949687957764\n",
      "[64 / 500] accuracy = 0.4916581545795029 loss = 0.6930123567581177\n",
      "[65 / 500] accuracy = 0.4916581545795029 loss = 0.6928256154060364\n",
      "[66 / 500] accuracy = 0.4916581545795029 loss = 0.6931713223457336\n",
      "[67 / 500] accuracy = 0.4916581545795029 loss = 0.6929319500923157\n",
      "[68 / 500] accuracy = 0.4916581545795029 loss = 0.6929776072502136\n",
      "[69 / 500] accuracy = 0.4916581545795029 loss = 0.6930893659591675\n",
      "[70 / 500] accuracy = 0.4916581545795029 loss = 0.6931167840957642\n",
      "[71 / 500] accuracy = 0.4916581545795029 loss = 0.6931816935539246\n",
      "[72 / 500] accuracy = 0.4916581545795029 loss = 0.6931066513061523\n",
      "[73 / 500] accuracy = 0.4916581545795029 loss = 0.6931132078170776\n",
      "[74 / 500] accuracy = 0.4916581545795029 loss = 0.6930598020553589\n",
      "[75 / 500] accuracy = 0.4916581545795029 loss = 0.6930690407752991\n",
      "[76 / 500] accuracy = 0.4916581545795029 loss = 0.6930711269378662\n",
      "[77 / 500] accuracy = 0.4916581545795029 loss = 0.6934618949890137\n",
      "[78 / 500] accuracy = 0.4916581545795029 loss = 0.6929512619972229\n",
      "[79 / 500] accuracy = 0.4916581545795029 loss = 0.6934229135513306\n",
      "[80 / 500] accuracy = 0.4916581545795029 loss = 0.6929779648780823\n",
      "[81 / 500] accuracy = 0.4916581545795029 loss = 0.6929686069488525\n",
      "[82 / 500] accuracy = 0.4916581545795029 loss = 0.6929261088371277\n",
      "[83 / 500] accuracy = 0.4916581545795029 loss = 0.6931712627410889\n",
      "[84 / 500] accuracy = 0.4916581545795029 loss = 0.6930751204490662\n",
      "[85 / 500] accuracy = 0.4916581545795029 loss = 0.693091094493866\n",
      "[86 / 500] accuracy = 0.4916581545795029 loss = 0.6930716037750244\n",
      "[87 / 500] accuracy = 0.4916581545795029 loss = 0.6931331157684326\n",
      "[88 / 500] accuracy = 0.4916581545795029 loss = 0.6933406591415405\n",
      "[89 / 500] accuracy = 0.4916581545795029 loss = 0.693442165851593\n",
      "[90 / 500] accuracy = 0.4916581545795029 loss = 0.6934177279472351\n",
      "[91 / 500] accuracy = 0.4916581545795029 loss = 0.6932022571563721\n",
      "[92 / 500] accuracy = 0.4916581545795029 loss = 0.6930786371231079\n",
      "[93 / 500] accuracy = 0.4916581545795029 loss = 0.693099319934845\n",
      "[94 / 500] accuracy = 0.4916581545795029 loss = 0.6934258341789246\n",
      "[95 / 500] accuracy = 0.4916581545795029 loss = 0.6929247975349426\n",
      "[96 / 500] accuracy = 0.4916581545795029 loss = 0.6930660009384155\n",
      "[97 / 500] accuracy = 0.4916581545795029 loss = 0.6931373476982117\n",
      "[98 / 500] accuracy = 0.4916581545795029 loss = 0.6930069327354431\n",
      "[99 / 500] accuracy = 0.4916581545795029 loss = 0.6931754946708679\n",
      "[100 / 500] accuracy = 0.4916581545795029 loss = 0.6929215788841248\n",
      "[101 / 500] accuracy = 0.4916581545795029 loss = 0.6930749416351318\n",
      "[102 / 500] accuracy = 0.4916581545795029 loss = 0.693252682685852\n",
      "[103 / 500] accuracy = 0.4916581545795029 loss = 0.692965030670166\n",
      "[104 / 500] accuracy = 0.4916581545795029 loss = 0.6930834650993347\n",
      "[105 / 500] accuracy = 0.4916581545795029 loss = 0.6930201053619385\n",
      "[106 / 500] accuracy = 0.4916581545795029 loss = 0.6929553151130676\n",
      "[107 / 500] accuracy = 0.4916581545795029 loss = 0.6930232048034668\n",
      "[108 / 500] accuracy = 0.4916581545795029 loss = 0.6929645538330078\n",
      "[109 / 500] accuracy = 0.4916581545795029 loss = 0.6930233836174011\n",
      "[110 / 500] accuracy = 0.4916581545795029 loss = 0.6929394602775574\n",
      "[111 / 500] accuracy = 0.4916581545795029 loss = 0.6931094527244568\n",
      "[112 / 500] accuracy = 0.4916581545795029 loss = 0.6934967637062073\n",
      "[113 / 500] accuracy = 0.4916581545795029 loss = 0.6930577158927917\n",
      "[114 / 500] accuracy = 0.4916581545795029 loss = 0.6929477453231812\n",
      "[115 / 500] accuracy = 0.4916581545795029 loss = 0.6929725408554077\n",
      "[116 / 500] accuracy = 0.4916581545795029 loss = 0.6929402351379395\n",
      "[117 / 500] accuracy = 0.4916581545795029 loss = 0.6931004524230957\n",
      "[118 / 500] accuracy = 0.4916581545795029 loss = 0.6929813027381897\n",
      "[119 / 500] accuracy = 0.4916581545795029 loss = 0.6929107308387756\n",
      "[120 / 500] accuracy = 0.4916581545795029 loss = 0.6931270360946655\n",
      "[121 / 500] accuracy = 0.4916581545795029 loss = 0.6929604411125183\n",
      "[122 / 500] accuracy = 0.4916581545795029 loss = 0.6930854320526123\n",
      "[123 / 500] accuracy = 0.4916581545795029 loss = 0.6927688121795654\n",
      "[124 / 500] accuracy = 0.4916581545795029 loss = 0.6930490732192993\n",
      "[125 / 500] accuracy = 0.4916581545795029 loss = 0.6926104426383972\n",
      "[126 / 500] accuracy = 0.4916581545795029 loss = 0.6932081580162048\n",
      "[127 / 500] accuracy = 0.4916581545795029 loss = 0.6932886838912964\n",
      "[128 / 500] accuracy = 0.4916581545795029 loss = 0.6929639577865601\n",
      "[129 / 500] accuracy = 0.4916581545795029 loss = 0.692884624004364\n",
      "[130 / 500] accuracy = 0.4916581545795029 loss = 0.6931321620941162\n",
      "[131 / 500] accuracy = 0.4916581545795029 loss = 0.69307941198349\n",
      "[132 / 500] accuracy = 0.4916581545795029 loss = 0.6928271651268005\n",
      "[133 / 500] accuracy = 0.4916581545795029 loss = 0.6928105354309082\n",
      "[134 / 500] accuracy = 0.4916581545795029 loss = 0.692969024181366\n",
      "[135 / 500] accuracy = 0.4916581545795029 loss = 0.693642258644104\n",
      "[136 / 500] accuracy = 0.4916581545795029 loss = 0.6927230358123779\n",
      "[137 / 500] accuracy = 0.4916581545795029 loss = 0.6929398775100708\n",
      "[138 / 500] accuracy = 0.4916581545795029 loss = 0.6931104063987732\n",
      "[139 / 500] accuracy = 0.4916581545795029 loss = 0.6927201151847839\n",
      "[140 / 500] accuracy = 0.4916581545795029 loss = 0.6925806999206543\n",
      "[141 / 500] accuracy = 0.4916581545795029 loss = 0.6927416920661926\n",
      "[142 / 500] accuracy = 0.4916581545795029 loss = 0.6926907896995544\n",
      "[143 / 500] accuracy = 0.4916581545795029 loss = 0.6927317380905151\n",
      "[144 / 500] accuracy = 0.4916581545795029 loss = 0.6920813322067261\n",
      "[145 / 500] accuracy = 0.4916581545795029 loss = 0.692054033279419\n",
      "[146 / 500] accuracy = 0.4916581545795029 loss = 0.6927388906478882\n",
      "[147 / 500] accuracy = 0.4916581545795029 loss = 0.6922025084495544\n",
      "[148 / 500] accuracy = 0.4916581545795029 loss = 0.6923797130584717\n",
      "[149 / 500] accuracy = 0.4916581545795029 loss = 0.6932404637336731\n",
      "[150 / 500] accuracy = 0.4916581545795029 loss = 0.6923971772193909\n",
      "[151 / 500] accuracy = 0.4916581545795029 loss = 0.6923729777336121\n",
      "[152 / 500] accuracy = 0.4916581545795029 loss = 0.6926202178001404\n",
      "[153 / 500] accuracy = 0.4916581545795029 loss = 0.6924675703048706\n",
      "[154 / 500] accuracy = 0.4916581545795029 loss = 0.6923572421073914\n",
      "[155 / 500] accuracy = 0.4916581545795029 loss = 0.6928851008415222\n",
      "[156 / 500] accuracy = 0.4916581545795029 loss = 0.6915070414543152\n",
      "[157 / 500] accuracy = 0.4916581545795029 loss = 0.6914432048797607\n",
      "[158 / 500] accuracy = 0.4916581545795029 loss = 0.6911656856536865\n",
      "[159 / 500] accuracy = 0.4916581545795029 loss = 0.6909646391868591\n",
      "[160 / 500] accuracy = 0.4916581545795029 loss = 0.6898549795150757\n",
      "[161 / 500] accuracy = 0.4916581545795029 loss = 0.690285325050354\n",
      "[162 / 500] accuracy = 0.4916581545795029 loss = 0.6903691291809082\n",
      "[163 / 500] accuracy = 0.4916581545795029 loss = 0.687444269657135\n",
      "[164 / 500] accuracy = 0.4916581545795029 loss = 0.680909276008606\n",
      "[165 / 500] accuracy = 0.4916581545795029 loss = 0.6877630949020386\n",
      "[166 / 500] accuracy = 0.4916581545795029 loss = 0.6836022734642029\n",
      "[167 / 500] accuracy = 0.4916581545795029 loss = 0.6692669987678528\n",
      "[168 / 500] accuracy = 0.4916581545795029 loss = 0.6436182260513306\n",
      "[169 / 500] accuracy = 0.4916581545795029 loss = 0.5873075127601624\n",
      "[170 / 500] accuracy = 0.4916581545795029 loss = 0.4770275056362152\n",
      "[171 / 500] accuracy = 0.4916581545795029 loss = 0.5068442225456238\n",
      "[172 / 500] accuracy = 0.4916581545795029 loss = 0.5380519032478333\n",
      "[173 / 500] accuracy = 0.4916581545795029 loss = 0.4432792663574219\n",
      "[174 / 500] accuracy = 0.4916581545795029 loss = 0.36595118045806885\n",
      "[175 / 500] accuracy = 0.4916581545795029 loss = 0.3467200994491577\n",
      "[176 / 500] accuracy = 0.4916581545795029 loss = 0.49750611186027527\n",
      "[177 / 500] accuracy = 0.4916581545795029 loss = 0.38072800636291504\n",
      "[178 / 500] accuracy = 0.4916581545795029 loss = 0.2827387750148773\n",
      "[179 / 500] accuracy = 0.4916581545795029 loss = 0.38896444439888\n",
      "[180 / 500] accuracy = 0.4916581545795029 loss = 0.36819443106651306\n",
      "[181 / 500] accuracy = 0.4916581545795029 loss = 0.28335806727409363\n",
      "[182 / 500] accuracy = 0.4916581545795029 loss = 0.2977411150932312\n",
      "[183 / 500] accuracy = 0.4919986380660538 loss = 0.27921822667121887\n",
      "[184 / 500] accuracy = 0.4919986380660538 loss = 0.3577083647251129\n",
      "[185 / 500] accuracy = 0.4916581545795029 loss = 0.20711840689182281\n",
      "[186 / 500] accuracy = 0.4916581545795029 loss = 0.23142684996128082\n",
      "[187 / 500] accuracy = 0.4916581545795029 loss = 0.2564350366592407\n",
      "[188 / 500] accuracy = 0.4916581545795029 loss = 0.23204056918621063\n",
      "[189 / 500] accuracy = 0.4916581545795029 loss = 0.2003222107887268\n",
      "[190 / 500] accuracy = 0.4916581545795029 loss = 0.29358384013175964\n",
      "[191 / 500] accuracy = 0.4916581545795029 loss = 0.2895810902118683\n",
      "[192 / 500] accuracy = 0.4916581545795029 loss = 0.26594942808151245\n",
      "[193 / 500] accuracy = 0.4916581545795029 loss = 0.24827435612678528\n",
      "[194 / 500] accuracy = 0.4916581545795029 loss = 0.2796317934989929\n",
      "[195 / 500] accuracy = 0.4916581545795029 loss = 0.1934521645307541\n",
      "[196 / 500] accuracy = 0.4916581545795029 loss = 0.23615598678588867\n",
      "[197 / 500] accuracy = 0.4919986380660538 loss = 0.20450112223625183\n",
      "[198 / 500] accuracy = 0.4919986380660538 loss = 0.22533096373081207\n",
      "[199 / 500] accuracy = 0.4916581545795029 loss = 0.22274917364120483\n",
      "[200 / 500] accuracy = 0.4916581545795029 loss = 0.20346598327159882\n",
      "[201 / 500] accuracy = 0.4919986380660538 loss = 0.1974381059408188\n",
      "[202 / 500] accuracy = 0.4919986380660538 loss = 0.19159968197345734\n",
      "[203 / 500] accuracy = 0.4916581545795029 loss = 0.17236092686653137\n",
      "[204 / 500] accuracy = 0.4916581545795029 loss = 0.23921877145767212\n",
      "[205 / 500] accuracy = 0.4916581545795029 loss = 0.19136328995227814\n",
      "[206 / 500] accuracy = 0.4916581545795029 loss = 0.286727637052536\n",
      "[207 / 500] accuracy = 0.4916581545795029 loss = 0.2685890197753906\n",
      "[208 / 500] accuracy = 0.4916581545795029 loss = 0.13157683610916138\n",
      "[209 / 500] accuracy = 0.4916581545795029 loss = 0.25236597657203674\n",
      "[210 / 500] accuracy = 0.4916581545795029 loss = 0.22543101012706757\n",
      "[211 / 500] accuracy = 0.4916581545795029 loss = 0.21987393498420715\n",
      "[212 / 500] accuracy = 0.4916581545795029 loss = 0.1656484305858612\n",
      "[213 / 500] accuracy = 0.4916581545795029 loss = 0.16928303241729736\n",
      "[214 / 500] accuracy = 0.4916581545795029 loss = 0.21310456097126007\n",
      "[215 / 500] accuracy = 0.4916581545795029 loss = 0.23179373145103455\n",
      "[216 / 500] accuracy = 0.4916581545795029 loss = 0.15254810452461243\n",
      "[217 / 500] accuracy = 0.4916581545795029 loss = 0.16589444875717163\n",
      "[218 / 500] accuracy = 0.4916581545795029 loss = 0.25854137539863586\n",
      "[219 / 500] accuracy = 0.4916581545795029 loss = 0.19435036182403564\n",
      "[220 / 500] accuracy = 0.4916581545795029 loss = 0.29012781381607056\n",
      "[221 / 500] accuracy = 0.4916581545795029 loss = 0.16613994538784027\n",
      "[222 / 500] accuracy = 0.4916581545795029 loss = 0.13113634288311005\n",
      "[223 / 500] accuracy = 0.4916581545795029 loss = 0.11743276566267014\n",
      "[224 / 500] accuracy = 0.4916581545795029 loss = 0.1592390388250351\n",
      "[225 / 500] accuracy = 0.4916581545795029 loss = 0.22766412794589996\n",
      "[226 / 500] accuracy = 0.4916581545795029 loss = 0.24221262335777283\n",
      "[227 / 500] accuracy = 0.4916581545795029 loss = 0.13451337814331055\n",
      "[228 / 500] accuracy = 0.4916581545795029 loss = 0.11616682261228561\n",
      "[229 / 500] accuracy = 0.4916581545795029 loss = 0.15689165890216827\n",
      "[230 / 500] accuracy = 0.4916581545795029 loss = 0.2440127730369568\n",
      "[231 / 500] accuracy = 0.4916581545795029 loss = 0.1787119060754776\n",
      "[232 / 500] accuracy = 0.4916581545795029 loss = 0.15067967772483826\n",
      "[233 / 500] accuracy = 0.4916581545795029 loss = 0.14238792657852173\n",
      "[234 / 500] accuracy = 0.4916581545795029 loss = 0.18708980083465576\n",
      "[235 / 500] accuracy = 0.4916581545795029 loss = 0.18610556423664093\n",
      "[236 / 500] accuracy = 0.4916581545795029 loss = 0.11793700605630875\n",
      "[237 / 500] accuracy = 0.4916581545795029 loss = 0.23455895483493805\n",
      "[238 / 500] accuracy = 0.4916581545795029 loss = 0.25108158588409424\n",
      "[239 / 500] accuracy = 0.4919986380660538 loss = 0.12474970519542694\n",
      "[240 / 500] accuracy = 0.4919986380660538 loss = 0.13986891508102417\n",
      "[241 / 500] accuracy = 0.4916581545795029 loss = 0.1922774314880371\n",
      "[242 / 500] accuracy = 0.4916581545795029 loss = 0.22795385122299194\n",
      "[243 / 500] accuracy = 0.4916581545795029 loss = 0.14746426045894623\n",
      "[244 / 500] accuracy = 0.4916581545795029 loss = 0.13944481313228607\n",
      "[245 / 500] accuracy = 0.4916581545795029 loss = 0.17289772629737854\n",
      "[246 / 500] accuracy = 0.4916581545795029 loss = 0.17455096542835236\n",
      "[247 / 500] accuracy = 0.4916581545795029 loss = 0.17144422233104706\n",
      "[248 / 500] accuracy = 0.4916581545795029 loss = 0.17256411910057068\n",
      "[249 / 500] accuracy = 0.4916581545795029 loss = 0.119880810379982\n",
      "[250 / 500] accuracy = 0.4916581545795029 loss = 0.11658121645450592\n",
      "[251 / 500] accuracy = 0.4916581545795029 loss = 0.15664075314998627\n",
      "[252 / 500] accuracy = 0.4916581545795029 loss = 0.21133725345134735\n",
      "[253 / 500] accuracy = 0.4916581545795029 loss = 0.15992604196071625\n",
      "[254 / 500] accuracy = 0.4916581545795029 loss = 0.16955217719078064\n",
      "[255 / 500] accuracy = 0.4916581545795029 loss = 0.17293186485767365\n",
      "[256 / 500] accuracy = 0.4916581545795029 loss = 0.17363347113132477\n",
      "[257 / 500] accuracy = 0.4916581545795029 loss = 0.18983159959316254\n",
      "[258 / 500] accuracy = 0.4916581545795029 loss = 0.11342328786849976\n",
      "[259 / 500] accuracy = 0.4916581545795029 loss = 0.37196075916290283\n",
      "[260 / 500] accuracy = 0.4916581545795029 loss = 0.09982462227344513\n",
      "[261 / 500] accuracy = 0.4916581545795029 loss = 0.07354366779327393\n",
      "[262 / 500] accuracy = 0.4916581545795029 loss = 0.16038495302200317\n",
      "[263 / 500] accuracy = 0.4919986380660538 loss = 0.17778779566287994\n",
      "[264 / 500] accuracy = 0.4919986380660538 loss = 0.21591328084468842\n",
      "[265 / 500] accuracy = 0.4916581545795029 loss = 0.10432840883731842\n",
      "[266 / 500] accuracy = 0.4916581545795029 loss = 0.27502351999282837\n",
      "[267 / 500] accuracy = 0.4919986380660538 loss = 0.2377156764268875\n",
      "[268 / 500] accuracy = 0.4919986380660538 loss = 0.08319024741649628\n",
      "[269 / 500] accuracy = 0.4916581545795029 loss = 0.18009021878242493\n",
      "[270 / 500] accuracy = 0.4916581545795029 loss = 0.25687769055366516\n",
      "[271 / 500] accuracy = 0.4916581545795029 loss = 0.11957185715436935\n",
      "[272 / 500] accuracy = 0.4916581545795029 loss = 0.23570293188095093\n",
      "[273 / 500] accuracy = 0.4916581545795029 loss = 0.22311784327030182\n",
      "[274 / 500] accuracy = 0.4916581545795029 loss = 0.1415504813194275\n",
      "[275 / 500] accuracy = 0.4916581545795029 loss = 0.18463613092899323\n",
      "[276 / 500] accuracy = 0.4916581545795029 loss = 0.12018509209156036\n",
      "[277 / 500] accuracy = 0.4916581545795029 loss = 0.22635751962661743\n",
      "[278 / 500] accuracy = 0.4916581545795029 loss = 0.14228251576423645\n",
      "[279 / 500] accuracy = 0.4916581545795029 loss = 0.23745839297771454\n",
      "[280 / 500] accuracy = 0.4916581545795029 loss = 0.16000531613826752\n",
      "[281 / 500] accuracy = 0.4916581545795029 loss = 0.12398688495159149\n",
      "[282 / 500] accuracy = 0.4916581545795029 loss = 0.11867224425077438\n",
      "[283 / 500] accuracy = 0.4916581545795029 loss = 0.17462870478630066\n",
      "[284 / 500] accuracy = 0.4916581545795029 loss = 0.16731873154640198\n",
      "[285 / 500] accuracy = 0.4916581545795029 loss = 0.15832610428333282\n",
      "[286 / 500] accuracy = 0.4916581545795029 loss = 0.18278814852237701\n",
      "[287 / 500] accuracy = 0.4916581545795029 loss = 0.08362302929162979\n",
      "[288 / 500] accuracy = 0.4916581545795029 loss = 0.1440982222557068\n",
      "[289 / 500] accuracy = 0.4916581545795029 loss = 0.14906595647335052\n",
      "[290 / 500] accuracy = 0.4916581545795029 loss = 0.09078080207109451\n",
      "[291 / 500] accuracy = 0.4916581545795029 loss = 0.17604665458202362\n",
      "[292 / 500] accuracy = 0.4916581545795029 loss = 0.100432850420475\n",
      "[293 / 500] accuracy = 0.4919986380660538 loss = 0.11904145777225494\n",
      "[294 / 500] accuracy = 0.4919986380660538 loss = 0.07754619419574738\n",
      "[295 / 500] accuracy = 0.4916581545795029 loss = 0.16146160662174225\n",
      "[296 / 500] accuracy = 0.4916581545795029 loss = 0.16592058539390564\n",
      "[297 / 500] accuracy = 0.4916581545795029 loss = 0.19752854108810425\n",
      "[298 / 500] accuracy = 0.4916581545795029 loss = 0.08764433860778809\n",
      "[299 / 500] accuracy = 0.4916581545795029 loss = 0.16482454538345337\n",
      "[300 / 500] accuracy = 0.4916581545795029 loss = 0.08715201914310455\n",
      "[301 / 500] accuracy = 0.4916581545795029 loss = 0.2805829346179962\n",
      "[302 / 500] accuracy = 0.4916581545795029 loss = 0.18267017602920532\n",
      "[303 / 500] accuracy = 0.4916581545795029 loss = 0.15696878731250763\n",
      "[304 / 500] accuracy = 0.4916581545795029 loss = 0.15486353635787964\n",
      "[305 / 500] accuracy = 0.4919986380660538 loss = 0.11275523900985718\n",
      "[306 / 500] accuracy = 0.4919986380660538 loss = 0.13831011950969696\n",
      "[307 / 500] accuracy = 0.4916581545795029 loss = 0.09723018854856491\n",
      "[308 / 500] accuracy = 0.4916581545795029 loss = 0.21333405375480652\n",
      "[309 / 500] accuracy = 0.4916581545795029 loss = 0.19913816452026367\n",
      "[310 / 500] accuracy = 0.4916581545795029 loss = 0.0967157706618309\n",
      "[311 / 500] accuracy = 0.4916581545795029 loss = 0.15297351777553558\n",
      "[312 / 500] accuracy = 0.4916581545795029 loss = 0.22678032517433167\n",
      "[313 / 500] accuracy = 0.4916581545795029 loss = 0.17896099388599396\n",
      "[314 / 500] accuracy = 0.4916581545795029 loss = 0.11835124343633652\n",
      "[315 / 500] accuracy = 0.4916581545795029 loss = 0.21246014535427094\n",
      "[316 / 500] accuracy = 0.4916581545795029 loss = 0.0857107862830162\n",
      "[317 / 500] accuracy = 0.4916581545795029 loss = 0.07908736169338226\n",
      "[318 / 500] accuracy = 0.4916581545795029 loss = 0.0991721898317337\n",
      "[319 / 500] accuracy = 0.4916581545795029 loss = 0.09076538681983948\n",
      "[320 / 500] accuracy = 0.4916581545795029 loss = 0.15175531804561615\n",
      "[321 / 500] accuracy = 0.4916581545795029 loss = 0.14893557131290436\n",
      "[322 / 500] accuracy = 0.4916581545795029 loss = 0.10867640376091003\n",
      "[323 / 500] accuracy = 0.4916581545795029 loss = 0.09810623526573181\n",
      "[324 / 500] accuracy = 0.4916581545795029 loss = 0.1961517035961151\n",
      "[325 / 500] accuracy = 0.4919986380660538 loss = 0.12702327966690063\n",
      "[326 / 500] accuracy = 0.4919986380660538 loss = 0.1695498675107956\n",
      "[327 / 500] accuracy = 0.4923391215526047 loss = 0.1466502696275711\n",
      "[328 / 500] accuracy = 0.4923391215526047 loss = 0.052659615874290466\n",
      "[329 / 500] accuracy = 0.4916581545795029 loss = 0.2734187841415405\n",
      "[330 / 500] accuracy = 0.4916581545795029 loss = 0.15408508479595184\n",
      "[331 / 500] accuracy = 0.4916581545795029 loss = 0.12858889997005463\n",
      "[332 / 500] accuracy = 0.4916581545795029 loss = 0.14684602618217468\n",
      "[333 / 500] accuracy = 0.4919986380660538 loss = 0.08252207934856415\n",
      "[334 / 500] accuracy = 0.4919986380660538 loss = 0.20856934785842896\n",
      "[335 / 500] accuracy = 0.4916581545795029 loss = 0.1249040886759758\n",
      "[336 / 500] accuracy = 0.4916581545795029 loss = 0.27434632182121277\n",
      "[337 / 500] accuracy = 0.4916581545795029 loss = 0.11960535496473312\n",
      "[338 / 500] accuracy = 0.4916581545795029 loss = 0.15312744677066803\n",
      "[339 / 500] accuracy = 0.4923391215526047 loss = 0.09882555156946182\n",
      "[340 / 500] accuracy = 0.4923391215526047 loss = 0.12789028882980347\n",
      "[341 / 500] accuracy = 0.4916581545795029 loss = 0.23329928517341614\n",
      "[342 / 500] accuracy = 0.4916581545795029 loss = 0.08565560728311539\n",
      "[343 / 500] accuracy = 0.4919986380660538 loss = 0.1192736104130745\n",
      "[344 / 500] accuracy = 0.4919986380660538 loss = 0.1775769591331482\n",
      "[345 / 500] accuracy = 0.4919986380660538 loss = 0.11238527297973633\n",
      "[346 / 500] accuracy = 0.4919986380660538 loss = 0.11421413719654083\n",
      "[347 / 500] accuracy = 0.4916581545795029 loss = 0.18285535275936127\n",
      "[348 / 500] accuracy = 0.4916581545795029 loss = 0.20775708556175232\n",
      "[349 / 500] accuracy = 0.4919986380660538 loss = 0.07124283164739609\n",
      "[350 / 500] accuracy = 0.4919986380660538 loss = 0.14856857061386108\n",
      "[351 / 500] accuracy = 0.4916581545795029 loss = 0.1779073178768158\n",
      "[352 / 500] accuracy = 0.4916581545795029 loss = 0.1973336637020111\n",
      "[353 / 500] accuracy = 0.4916581545795029 loss = 0.1325588822364807\n",
      "[354 / 500] accuracy = 0.4916581545795029 loss = 0.13633672893047333\n",
      "[355 / 500] accuracy = 0.4923391215526047 loss = 0.14480414986610413\n",
      "[356 / 500] accuracy = 0.4923391215526047 loss = 0.09480610489845276\n",
      "[357 / 500] accuracy = 0.4919986380660538 loss = 0.12032455950975418\n",
      "[358 / 500] accuracy = 0.4919986380660538 loss = 0.09032706916332245\n",
      "[359 / 500] accuracy = 0.4916581545795029 loss = 0.12309961020946503\n",
      "[360 / 500] accuracy = 0.4916581545795029 loss = 0.0908912718296051\n",
      "[361 / 500] accuracy = 0.4919986380660538 loss = 0.13085469603538513\n",
      "[362 / 500] accuracy = 0.4919986380660538 loss = 0.07675998657941818\n",
      "[363 / 500] accuracy = 0.4933605720122574 loss = 0.0783841460943222\n",
      "[364 / 500] accuracy = 0.4933605720122574 loss = 0.16207563877105713\n",
      "[365 / 500] accuracy = 0.4916581545795029 loss = 0.11422980576753616\n",
      "[366 / 500] accuracy = 0.4916581545795029 loss = 0.1274714320898056\n",
      "[367 / 500] accuracy = 0.4919986380660538 loss = 0.07421816885471344\n",
      "[368 / 500] accuracy = 0.4919986380660538 loss = 0.19352826476097107\n",
      "[369 / 500] accuracy = 0.4916581545795029 loss = 0.1805601269006729\n",
      "[370 / 500] accuracy = 0.4916581545795029 loss = 0.24719581007957458\n",
      "[371 / 500] accuracy = 0.4923391215526047 loss = 0.1072622761130333\n",
      "[372 / 500] accuracy = 0.4923391215526047 loss = 0.10479993373155594\n",
      "[373 / 500] accuracy = 0.4933605720122574 loss = 0.11421089619398117\n",
      "[374 / 500] accuracy = 0.4933605720122574 loss = 0.1087033748626709\n",
      "[375 / 500] accuracy = 0.4926796050391556 loss = 0.03979511559009552\n",
      "[376 / 500] accuracy = 0.4926796050391556 loss = 0.0777597650885582\n",
      "[377 / 500] accuracy = 0.4916581545795029 loss = 0.17157022655010223\n",
      "[378 / 500] accuracy = 0.4916581545795029 loss = 0.09854736179113388\n",
      "[379 / 500] accuracy = 0.4919986380660538 loss = 0.11189039796590805\n",
      "[380 / 500] accuracy = 0.4919986380660538 loss = 0.13064780831336975\n",
      "[381 / 500] accuracy = 0.4919986380660538 loss = 0.1252862811088562\n",
      "[382 / 500] accuracy = 0.4919986380660538 loss = 0.2009171098470688\n",
      "[383 / 500] accuracy = 0.4933605720122574 loss = 0.11834847182035446\n",
      "[384 / 500] accuracy = 0.4933605720122574 loss = 0.0901414081454277\n",
      "[385 / 500] accuracy = 0.4923391215526047 loss = 0.17863966524600983\n",
      "[386 / 500] accuracy = 0.4923391215526047 loss = 0.07941517978906631\n",
      "[387 / 500] accuracy = 0.4933605720122574 loss = 0.06885343044996262\n",
      "[388 / 500] accuracy = 0.4933605720122574 loss = 0.19459085166454315\n",
      "[389 / 500] accuracy = 0.4916581545795029 loss = 0.11011216044425964\n",
      "[390 / 500] accuracy = 0.4916581545795029 loss = 0.13438302278518677\n",
      "[391 / 500] accuracy = 0.4923391215526047 loss = 0.12598834931850433\n",
      "[392 / 500] accuracy = 0.4923391215526047 loss = 0.15233910083770752\n",
      "[393 / 500] accuracy = 0.4923391215526047 loss = 0.1576932966709137\n",
      "[394 / 500] accuracy = 0.4923391215526047 loss = 0.09266895800828934\n",
      "[395 / 500] accuracy = 0.4919986380660538 loss = 0.07121434807777405\n",
      "[396 / 500] accuracy = 0.4919986380660538 loss = 0.1484401673078537\n",
      "[397 / 500] accuracy = 0.4937010554988083 loss = 0.07960361987352371\n",
      "[398 / 500] accuracy = 0.4937010554988083 loss = 0.1528293937444687\n",
      "[399 / 500] accuracy = 0.4923391215526047 loss = 0.05797569081187248\n",
      "[400 / 500] accuracy = 0.4923391215526047 loss = 0.10877365618944168\n",
      "[401 / 500] accuracy = 0.4916581545795029 loss = 0.050286538898944855\n",
      "[402 / 500] accuracy = 0.4916581545795029 loss = 0.09054378420114517\n",
      "[403 / 500] accuracy = 0.4919986380660538 loss = 0.1316678524017334\n",
      "[404 / 500] accuracy = 0.4919986380660538 loss = 0.18749244511127472\n",
      "[405 / 500] accuracy = 0.4916581545795029 loss = 0.08858653157949448\n",
      "[406 / 500] accuracy = 0.4916581545795029 loss = 0.158969447016716\n",
      "[407 / 500] accuracy = 0.4916581545795029 loss = 0.0825657919049263\n",
      "[408 / 500] accuracy = 0.4916581545795029 loss = 0.1256074607372284\n",
      "[409 / 500] accuracy = 0.4919986380660538 loss = 0.10774552077054977\n",
      "[410 / 500] accuracy = 0.4919986380660538 loss = 0.09109507501125336\n",
      "[411 / 500] accuracy = 0.4950629894450119 loss = 0.08281650394201279\n",
      "[412 / 500] accuracy = 0.4950629894450119 loss = 0.10623472183942795\n",
      "[413 / 500] accuracy = 0.4937010554988083 loss = 0.2148135006427765\n",
      "[414 / 500] accuracy = 0.4937010554988083 loss = 0.1536678522825241\n",
      "[415 / 500] accuracy = 0.4926796050391556 loss = 0.08670897036790848\n",
      "[416 / 500] accuracy = 0.4926796050391556 loss = 0.07602407038211823\n",
      "[417 / 500] accuracy = 0.4933605720122574 loss = 0.10374180227518082\n",
      "[418 / 500] accuracy = 0.4933605720122574 loss = 0.07809532433748245\n",
      "[419 / 500] accuracy = 0.4926796050391556 loss = 0.07809252291917801\n",
      "[420 / 500] accuracy = 0.4926796050391556 loss = 0.06735782325267792\n",
      "[421 / 500] accuracy = 0.4937010554988083 loss = 0.13891279697418213\n",
      "[422 / 500] accuracy = 0.4937010554988083 loss = 0.12343525141477585\n",
      "[423 / 500] accuracy = 0.49948927477017363 loss = 0.06923369318246841\n",
      "[424 / 500] accuracy = 0.49948927477017363 loss = 0.10533632338047028\n",
      "[425 / 500] accuracy = 0.49676540687776644 loss = 0.09351477771997452\n",
      "[426 / 500] accuracy = 0.49676540687776644 loss = 0.06250546872615814\n",
      "[427 / 500] accuracy = 0.4933605720122574 loss = 0.07450076192617416\n",
      "[428 / 500] accuracy = 0.4933605720122574 loss = 0.06941770762205124\n",
      "[429 / 500] accuracy = 0.4943820224719101 loss = 0.05368180200457573\n",
      "[430 / 500] accuracy = 0.4943820224719101 loss = 0.14397144317626953\n",
      "[431 / 500] accuracy = 0.4960844399046646 loss = 0.1854008287191391\n",
      "[432 / 500] accuracy = 0.4960844399046646 loss = 0.12671752274036407\n",
      "[433 / 500] accuracy = 0.4926796050391556 loss = 0.1299288123846054\n",
      "[434 / 500] accuracy = 0.4926796050391556 loss = 0.07618553936481476\n",
      "[435 / 500] accuracy = 0.4937010554988083 loss = 0.12462329864501953\n",
      "[436 / 500] accuracy = 0.4937010554988083 loss = 0.1022464856505394\n",
      "[437 / 500] accuracy = 0.4919986380660538 loss = 0.1628023386001587\n",
      "[438 / 500] accuracy = 0.4919986380660538 loss = 0.08045704662799835\n",
      "[439 / 500] accuracy = 0.4937010554988083 loss = 0.23835954070091248\n",
      "[440 / 500] accuracy = 0.4937010554988083 loss = 0.053406618535518646\n",
      "[441 / 500] accuracy = 0.4943820224719101 loss = 0.11651013791561127\n",
      "[442 / 500] accuracy = 0.4943820224719101 loss = 0.05137993395328522\n",
      "[443 / 500] accuracy = 0.4940415389853592 loss = 0.061035796999931335\n",
      "[444 / 500] accuracy = 0.4940415389853592 loss = 0.06996849179267883\n",
      "[445 / 500] accuracy = 0.49676540687776644 loss = 0.10822971165180206\n",
      "[446 / 500] accuracy = 0.49676540687776644 loss = 0.09168244153261185\n",
      "[447 / 500] accuracy = 0.4957439564181137 loss = 0.053266946226358414\n",
      "[448 / 500] accuracy = 0.4957439564181137 loss = 0.1040700376033783\n",
      "[449 / 500] accuracy = 0.49948927477017363 loss = 0.06496599316596985\n",
      "[450 / 500] accuracy = 0.49948927477017363 loss = 0.1190834641456604\n",
      "[451 / 500] accuracy = 0.49846782431052095 loss = 0.14037945866584778\n",
      "[452 / 500] accuracy = 0.49846782431052095 loss = 0.13260403275489807\n",
      "[453 / 500] accuracy = 0.4930200885257065 loss = 0.20441366732120514\n",
      "[454 / 500] accuracy = 0.4930200885257065 loss = 0.17751143872737885\n",
      "[455 / 500] accuracy = 0.50187265917603 loss = 0.13187240064144135\n",
      "[456 / 500] accuracy = 0.50187265917603 loss = 0.07850120961666107\n",
      "[457 / 500] accuracy = 0.5001702417432754 loss = 0.12117869406938553\n",
      "[458 / 500] accuracy = 0.5001702417432754 loss = 0.11264645308256149\n",
      "[459 / 500] accuracy = 0.4937010554988083 loss = 0.12082507461309433\n",
      "[460 / 500] accuracy = 0.4937010554988083 loss = 0.10703170299530029\n",
      "[461 / 500] accuracy = 0.49676540687776644 loss = 0.22232705354690552\n",
      "[462 / 500] accuracy = 0.49676540687776644 loss = 0.0821218341588974\n",
      "[463 / 500] accuracy = 0.4926796050391556 loss = 0.08591486513614655\n",
      "[464 / 500] accuracy = 0.4926796050391556 loss = 0.11430743336677551\n",
      "[465 / 500] accuracy = 0.49540347293156284 loss = 0.09347626566886902\n",
      "[466 / 500] accuracy = 0.49540347293156284 loss = 0.08248504251241684\n",
      "[467 / 500] accuracy = 0.5025536261491318 loss = 0.07807309925556183\n",
      "[468 / 500] accuracy = 0.5025536261491318 loss = 0.1526584029197693\n",
      "[469 / 500] accuracy = 0.4991487912836227 loss = 0.13316576182842255\n",
      "[470 / 500] accuracy = 0.4991487912836227 loss = 0.08015666157007217\n",
      "[471 / 500] accuracy = 0.49982975825672454 loss = 0.10798967629671097\n",
      "[472 / 500] accuracy = 0.49982975825672454 loss = 0.09709184616804123\n",
      "[473 / 500] accuracy = 0.49880830779707186 loss = 0.13237839937210083\n",
      "[474 / 500] accuracy = 0.49880830779707186 loss = 0.1155720129609108\n",
      "[475 / 500] accuracy = 0.4960844399046646 loss = 0.07356198877096176\n",
      "[476 / 500] accuracy = 0.4960844399046646 loss = 0.06760430335998535\n",
      "[477 / 500] accuracy = 0.5100442628532517 loss = 0.14669309556484222\n",
      "[478 / 500] accuracy = 0.5100442628532517 loss = 0.05634554848074913\n",
      "[479 / 500] accuracy = 0.49540347293156284 loss = 0.034567371010780334\n",
      "[480 / 500] accuracy = 0.49540347293156284 loss = 0.08819545060396194\n",
      "[481 / 500] accuracy = 0.5083418454204971 loss = 0.07135336846113205\n",
      "[482 / 500] accuracy = 0.5083418454204971 loss = 0.1630159318447113\n",
      "[483 / 500] accuracy = 0.4991487912836227 loss = 0.08894559741020203\n",
      "[484 / 500] accuracy = 0.4991487912836227 loss = 0.10369142144918442\n",
      "[485 / 500] accuracy = 0.49846782431052095 loss = 0.0912066176533699\n",
      "[486 / 500] accuracy = 0.49846782431052095 loss = 0.08678361028432846\n",
      "[487 / 500] accuracy = 0.4926796050391556 loss = 0.13182108104228973\n",
      "[488 / 500] accuracy = 0.4926796050391556 loss = 0.037793442606925964\n",
      "[489 / 500] accuracy = 0.4960844399046646 loss = 0.10990171879529953\n",
      "[490 / 500] accuracy = 0.4960844399046646 loss = 0.09077831357717514\n",
      "[491 / 500] accuracy = 0.5100442628532517 loss = 0.14466729760169983\n",
      "[492 / 500] accuracy = 0.5100442628532517 loss = 0.04483519122004509\n",
      "[493 / 500] accuracy = 0.4977868573374191 loss = 0.11494243890047073\n",
      "[494 / 500] accuracy = 0.4977868573374191 loss = 0.07184591889381409\n",
      "[495 / 500] accuracy = 0.49846782431052095 loss = 0.17505483329296112\n",
      "[496 / 500] accuracy = 0.49846782431052095 loss = 0.04978274181485176\n",
      "[497 / 500] accuracy = 0.5042560435818862 loss = 0.04419384151697159\n",
      "[498 / 500] accuracy = 0.5042560435818862 loss = 0.12287141382694244\n",
      "[499 / 500] accuracy = 0.49812734082397003 loss = 0.07171232998371124\n",
      "[500 / 500] accuracy = 0.49812734082397003 loss = 0.06733371317386627\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "weights_save = \"weights/yolo_class1\"\n",
    "losses = []\n",
    "iters = 0\n",
    "tests = []\n",
    "\n",
    "best = 0\n",
    "\n",
    "train_dataloader\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data[\"image\"], data[\"class\"]\n",
    "        labe_size = len(labels)\n",
    "        labels = labels.unsqueeze(1).to(torch.float32)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Pass model, backprop, optimize.\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print Stats\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 500 == 499:\n",
    "            # print(outputs, labels)\n",
    "            losses.append(running_loss / 500)\n",
    "\n",
    "            print(f'[{epoch + 1}, {i}] loss: {running_loss / 500}')\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # Save every epoch\n",
    "    save_path = os.path.join(weights_save, f\"{epoch}.pt\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "    # Run test at end of every 2 epoch\n",
    "    if epoch % 2 == 0:\n",
    "        test_ac = test()\n",
    "        if test_ac > best:\n",
    "            torch.save(model.state_dict(), weights_save + \"/best.pt\")\n",
    "            best = test_ac\n",
    "        tests.append(test_ac)\n",
    "\n",
    "    # Print stats\n",
    "    print(f\"[{epoch + 1} / {epochs}] accuracy = {test_ac} loss = {loss.item()}\")    \n",
    "    \n",
    "    \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_losses = [np.log10(i) for i in losses]\n",
    "plt.plot(log_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-377-f6ba78ce7d4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m     \"\"\"\n\u001b[0;32m-> 1188\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tests)\n",
    "np.argmax(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:1'"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model on the \"Test\" data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for WormClassifier:\n\tUnexpected key(s) in state_dict: \"fc2.weight\", \"fc2.bias\". \n\tsize mismatch for conv1_1.weight: copying a param with shape torch.Size([12, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([12, 1, 2, 2]).\n\tsize mismatch for conv1_2.weight: copying a param with shape torch.Size([12, 12, 5, 5]) from checkpoint, the shape in current model is torch.Size([12, 12, 2, 2]).\n\tsize mismatch for conv2_1.weight: copying a param with shape torch.Size([24, 12, 5, 5]) from checkpoint, the shape in current model is torch.Size([24, 12, 2, 2]).\n\tsize mismatch for conv2_2.weight: copying a param with shape torch.Size([24, 24, 5, 5]) from checkpoint, the shape in current model is torch.Size([24, 24, 2, 2]).\n\tsize mismatch for conv3_1.weight: copying a param with shape torch.Size([36, 24, 5, 5]) from checkpoint, the shape in current model is torch.Size([36, 24, 2, 2]).\n\tsize mismatch for conv3_2.weight: copying a param with shape torch.Size([36, 36, 5, 5]) from checkpoint, the shape in current model is torch.Size([36, 36, 2, 2]).\n\tsize mismatch for conv4_1.weight: copying a param with shape torch.Size([48, 36, 5, 5]) from checkpoint, the shape in current model is torch.Size([48, 36, 2, 2]).\n\tsize mismatch for conv4_2.weight: copying a param with shape torch.Size([48, 48, 5, 5]) from checkpoint, the shape in current model is torch.Size([48, 48, 2, 2]).\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([1, 192]).\n\tsize mismatch for fc1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-379-da31ab3ced5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWormClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weights/best-model.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1407\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for WormClassifier:\n\tUnexpected key(s) in state_dict: \"fc2.weight\", \"fc2.bias\". \n\tsize mismatch for conv1_1.weight: copying a param with shape torch.Size([12, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([12, 1, 2, 2]).\n\tsize mismatch for conv1_2.weight: copying a param with shape torch.Size([12, 12, 5, 5]) from checkpoint, the shape in current model is torch.Size([12, 12, 2, 2]).\n\tsize mismatch for conv2_1.weight: copying a param with shape torch.Size([24, 12, 5, 5]) from checkpoint, the shape in current model is torch.Size([24, 12, 2, 2]).\n\tsize mismatch for conv2_2.weight: copying a param with shape torch.Size([24, 24, 5, 5]) from checkpoint, the shape in current model is torch.Size([24, 24, 2, 2]).\n\tsize mismatch for conv3_1.weight: copying a param with shape torch.Size([36, 24, 5, 5]) from checkpoint, the shape in current model is torch.Size([36, 24, 2, 2]).\n\tsize mismatch for conv3_2.weight: copying a param with shape torch.Size([36, 36, 5, 5]) from checkpoint, the shape in current model is torch.Size([36, 36, 2, 2]).\n\tsize mismatch for conv4_1.weight: copying a param with shape torch.Size([48, 36, 5, 5]) from checkpoint, the shape in current model is torch.Size([48, 36, 2, 2]).\n\tsize mismatch for conv4_2.weight: copying a param with shape torch.Size([48, 48, 5, 5]) from checkpoint, the shape in current model is torch.Size([48, 48, 2, 2]).\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([1, 192]).\n\tsize mismatch for fc1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1])."
     ]
    }
   ],
   "source": [
    "# high_epoch = np.argmax(tests)\n",
    "# print(f\"best epoch = {tests[high_epoch]}\")\n",
    "\n",
    "# Load the best model\n",
    "best_model = WormClassifier(image_size)\n",
    "\n",
    "best_model.load_state_dict(torch.load(\"weights/best-model.pt\", map_location=device))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2352])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x2352 and 192x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-380-e5b3c73e76a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;31m# img.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-371-fa0c839e499e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# x = F.relu(self.fc1(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# x = F.relu(self.fc2(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x2352 and 192x1)"
     ]
    }
   ],
   "source": [
    "\n",
    "def validate():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_set:\n",
    "            img, labels = data[\"image\"], data[\"class\"]\n",
    "            img = img.unsqueeze(1)\n",
    "            # labels = labels.unsqueeze(1).to(torch.float32)\n",
    "            # labels = labels.to(device)\n",
    "\n",
    "            output = best_model(img)\n",
    "            output = output.squeeze(1)[0].to(int)\n",
    "            # print(output, labels)\n",
    "            if output == labels:\n",
    "                \n",
    "                correct += 1\n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "            total += 1\n",
    "    \n",
    "    return(correct / total)\n",
    "\n",
    "            \n",
    "#             for label, prediction in zip(labels, outputs):\n",
    "#                 prediction = prediction.to(torch.int)\n",
    "#                 if label == prediction:\n",
    "#                     correct += 1\n",
    "#                 else:\n",
    "#                     pass\n",
    "\n",
    "#                 total += 1\n",
    "\n",
    "#             # inputs, labels = data[\"image\"], data[\"class\"]\n",
    "    \n",
    "#     return(correct / total)\n",
    "\n",
    "\n",
    "sample = val_set[23]\n",
    "img = sample[\"image\"]\n",
    "label = sample[\"class\"]\n",
    "\n",
    "img = img.unsqueeze(1)\n",
    "pred = best_model(img)\n",
    "# img.shape\n",
    "acc = validate()\n",
    "print(acc)\n",
    "\n",
    "print(int(pred.squeeze(1)[0]) == 1)\n",
    "print(pred.squeeze(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'devicetorch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-50477dee9b12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdevicetorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'devicetorch' is not defined"
     ]
    }
   ],
   "source": [
    "devicetorch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.xpu of WormClassifier(\n",
       "  (conv1_1): Conv2d(1, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv1_2): Conv2d(12, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv2_1): Conv2d(12, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv2_2): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv3_1): Conv2d(24, 36, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv3_2): Conv2d(36, 36, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv4_1): Conv2d(36, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv4_2): Conv2d(48, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (fc1): Linear(in_features=192, out_features=1, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "\n",
    "model.xpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 26105.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "for v in tqdm(a):\n",
    "    print(v)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
